# markets/cn/sync_sw_cache_to_db.py
# -*- coding: utf-8 -*-
"""
Sync CN SW industry cache JSON -> sqlite stock_info

ç”¨é€”ï¼š
- è®€ markets/cn/cn_sw_merged_cache.json
- å°‡ sector / sw_l3 / sw_code å¯«å› markets/cn/cn_stock_warehouse.db çš„ stock_info
- é è¨­åªæ›´æ–°ã€Œç¼ºå¤±æˆ–å£å€¼ã€(only-missing) â€”â€” å¾ˆå¿«
- æ”¯æ´ dry-runã€çµ±è¨ˆã€ä»¥åŠè‡ªå‹•è£œæ¬„ä½(ALTER TABLE)

JSON æ ¼å¼ï¼ˆä½ ç›®å‰çš„ merged æª”ï¼‰ï¼š
data[symbol] = {
  "name": "...",
  "sector": "è‚¡ä»½åˆ¶é“¶è¡Œâ…¢",
  "sector_level": "l3",
  "sector_code": "857831.SI",
  "sw_l3": {"sw_code": "...", "sw_name": "..."}  # å¯æœ‰å¯ç„¡
}

æ³¨æ„ï¼š
- cache è£¡ sector å¯èƒ½æ˜¯ç©ºå­—ä¸²ï¼ˆunmappedï¼‰ï¼Œé€™ç¨®æœƒè·³éä¸å¯«
"""

from __future__ import annotations

import argparse
import json
import os
import sqlite3
from typing import Any, Dict, Iterable, List, Optional, Tuple

BAD_SECTOR = {"", "A-Share", "â€”", "-", "--", "ï¼", "â€“", None, "æœªåˆ†é¡"}


def _strip(x: Any) -> str:
    return str(x).strip() if x is not None else ""


def _default_db_path() -> str:
    return os.getenv("CN_DB_PATH", os.path.join(os.path.dirname(__file__), "cn_stock_warehouse.db"))


def _default_cache_path() -> str:
    return os.getenv("CN_SW_CACHE_PATH", os.path.join(os.path.dirname(__file__), "cn_sw_merged_cache.json"))


def _connect(db_path: str) -> sqlite3.Connection:
    return sqlite3.connect(db_path, timeout=120)


def _has_column(conn: sqlite3.Connection, table: str, col: str) -> bool:
    rows = conn.execute(f"PRAGMA table_info({table})").fetchall()
    cols = {r[1] for r in rows}
    return col in cols


def _ensure_columns(conn: sqlite3.Connection) -> None:
    """
    ç¢ºä¿ stock_info æœ‰ sw_l3 / sw_code æ¬„ä½ï¼ˆæ²’æœ‰å°±è£œï¼‰
    sector æ¬„ä½é€šå¸¸æœ¬ä¾†å°±æœ‰ï¼Œä½†ä¹Ÿåšä¿éšªæª¢æŸ¥
    """
    # stock_info å¿…é ˆå­˜åœ¨
    row = conn.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name='stock_info'"
    ).fetchone()
    if not row:
        raise RuntimeError("DB missing table: stock_info (è«‹å…ˆè·‘ downloader.run_sync å»ºè¡¨)")

    # sectorï¼ˆå¤§å¤šå·²å­˜åœ¨ï¼‰
    if not _has_column(conn, "stock_info", "sector"):
        conn.execute("ALTER TABLE stock_info ADD COLUMN sector TEXT")

    if not _has_column(conn, "stock_info", "sw_l3"):
        conn.execute("ALTER TABLE stock_info ADD COLUMN sw_l3 TEXT")

    if not _has_column(conn, "stock_info", "sw_code"):
        conn.execute("ALTER TABLE stock_info ADD COLUMN sw_code TEXT")


def _load_cache(cache_path: str) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    obj = json.loads(open(cache_path, "r", encoding="utf-8").read())
    meta = obj.get("_meta", {}) if isinstance(obj, dict) else {}
    data = obj.get("data", {}) if isinstance(obj, dict) else {}
    if not isinstance(data, dict):
        data = {}
    return data, meta


def _normalize_symbol(sym: str) -> str:
    """
    ä½  repo ç”¨çš„æ ¼å¼æ˜¯ 000001.SZ / 600000.SS
    cache ä¹ŸåŒæ¨£ã€‚
    é€™è£¡åªåš strip + upperã€‚
    """
    return _strip(sym).upper()


def _is_bad_sector(v: Any) -> bool:
    s = _strip(v)
    return (s in BAD_SECTOR) or (s == "")


def _build_updates_from_cache(
    cache_data: Dict[str, Any],
    *,
    only_missing: bool,
) -> Dict[str, Dict[str, str]]:
    """
    å›å‚³ mapping: symbol -> {"sector": ..., "sw_l3": ..., "sw_code": ...}
    åªç´å…¥ cache è£¡ sector éç©ºçš„è‚¡ç¥¨
    """
    out: Dict[str, Dict[str, str]] = {}
    for sym, item in cache_data.items():
        sym2 = _normalize_symbol(sym)
        if not sym2:
            continue
        if not isinstance(item, dict):
            continue

        sector = _strip(item.get("sector"))
        sw_code = _strip(item.get("sector_code")) or _strip(item.get("sector_code", ""))
        # ä½ çš„ json è£¡ sw_l3 é‚„å¯èƒ½æœ‰ sw_name/sw_codeï¼›ä½†æˆ‘å€‘å„ªå…ˆæ¡ sector/sector_code
        if not sector:
            continue  # unmapped -> è·³é

        out[sym2] = {"sector": sector, "sw_l3": sector, "sw_code": sw_code}

    return out


def _fetch_existing_info(conn: sqlite3.Connection) -> Dict[str, Dict[str, str]]:
    """
    å–å‡º stock_info ç›®å‰ sector/sw_l3/sw_codeï¼Œå›å‚³ dict
    """
    rows = conn.execute(
        "SELECT symbol, COALESCE(sector,''), COALESCE(sw_l3,''), COALESCE(sw_code,'') FROM stock_info"
    ).fetchall()
    m: Dict[str, Dict[str, str]] = {}
    for sym, sector, sw_l3, sw_code in rows:
        s = _normalize_symbol(sym)
        m[s] = {"sector": _strip(sector), "sw_l3": _strip(sw_l3), "sw_code": _strip(sw_code)}
    return m


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--db", default=_default_db_path(), help="sqlite db path")
    ap.add_argument("--cache", default=_default_cache_path(), help="cn_sw_merged_cache.json path")
    ap.add_argument("--only-missing", action="store_true", help="åªæ›´æ–° sector/sw ç¼ºå¤±æˆ–å£å€¼è€…ï¼ˆå»ºè­°ï¼‰")
    ap.add_argument("--full", action="store_true", help="å¼·åˆ¶å…¨é‡è¦†è“‹ï¼ˆä¸å»ºè­°ï¼Œé™¤éä½ è¦ä»¥ cache ç‚ºæº–ï¼‰")
    ap.add_argument("--dry-run", action="store_true", help="åªå°çµ±è¨ˆï¼Œä¸å¯« DB")
    ap.add_argument("--limit", type=int, default=0, help="åªæ›´æ–°å‰ N ç­†ï¼ˆæ¸¬è©¦ç”¨ï¼‰")
    args = ap.parse_args()

    only_missing = True
    if args.full:
        only_missing = False
    if args.only_missing:
        only_missing = True

    if not os.path.exists(args.cache):
        raise FileNotFoundError(f"Cache not found: {args.cache}")
    if not os.path.exists(args.db):
        raise FileNotFoundError(f"DB not found: {args.db}")

    cache_data, meta = _load_cache(args.cache)
    updates = _build_updates_from_cache(cache_data, only_missing=only_missing)

    conn = _connect(args.db)
    try:
        _ensure_columns(conn)
        conn.commit()

        existing = _fetch_existing_info(conn)

        # æ±ºå®šå“ªäº›è¦å¯«
        to_write: List[Tuple[str, str, str, str]] = []
        skip_not_in_db = 0
        skip_no_cache = 0
        skip_not_missing = 0

        for sym, u in updates.items():
            cur = existing.get(sym)
            if cur is None:
                skip_not_in_db += 1
                continue

            new_sector = u["sector"]
            new_sw_l3 = u["sw_l3"]
            new_sw_code = u["sw_code"]

            if only_missing:
                # åªæ›´æ–°ç¼ºå¤±/å£å€¼
                need = False
                if _is_bad_sector(cur.get("sector")):
                    need = True
                if _strip(cur.get("sw_l3")) == "":
                    need = True
                if _strip(cur.get("sw_code")) == "":
                    need = True

                if not need:
                    skip_not_missing += 1
                    continue

            to_write.append((new_sector, new_sw_l3, new_sw_code, sym))
            if args.limit and len(to_write) >= args.limit:
                break

        total_db = len(existing)
        total_cache = len(cache_data)
        total_updates = len(updates)
        planned = len(to_write)

        print("ğŸ“¦ DB:", args.db)
        print("ğŸ§¾ cache:", args.cache)
        print("ğŸ§¾ cache meta:", {k: meta.get(k) for k in ("generated_at", "total_symbols", "mapped_symbols", "unmapped_symbols")})
        print("ğŸ“Š DB stock_info symbols:", total_db)
        print("ğŸ“Š cache symbols:", total_cache)
        print("ğŸ“Š usable cache (sector non-empty):", total_updates)
        print("ğŸ¯ planned updates:", planned, "| only_missing=", only_missing, "| dry_run=", bool(args.dry_run))
        print("â­ï¸ skip_not_in_db:", skip_not_in_db, "| skip_not_missing:", skip_not_missing)

        if args.dry_run:
            print("ğŸ§ª dry-run: no DB writes.")
            return

        if planned == 0:
            print("âœ… nothing to update.")
            return

        conn.execute("BEGIN")
        conn.executemany(
            """
            UPDATE stock_info
            SET sector = ?,
                sw_l3  = ?,
                sw_code= ?
            WHERE symbol = ?
            """,
            to_write,
        )
        conn.commit()
        print(f"âœ… updated rows: {planned}")

    finally:
        conn.close()


if __name__ == "__main__":
    main()
